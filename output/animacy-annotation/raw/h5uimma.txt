Yes. It was very frustrating to hear Jeff make analogies like "we know how cars work" meaning ASI when they were supposed to be talking about AGIs. An AGI could be so fast and powerful that by the time we reverse engineered it to "know how it works" for a single decision, millions or more decisions could have been made and we would be hopelessly too late. Any outcome is possible and could be far beyond our comprehension that we would be the dogs in Sam's "dogs created humans" example.  

Jeff came across as incredibly arrogant and ignorant of what they were talking about. When talking about meeting people and the line "but you've never met a person who is orders of magnitude smarter than you" and Jeff say "well..." I died laughing. At first I thought it was him trying to make a joke, then he didn't. Jeff must understand what orders of magnitude is but he somehow claimed people are orders over each other when none of our general intelligence scales show those findings.
