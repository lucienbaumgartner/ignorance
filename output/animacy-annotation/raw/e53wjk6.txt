Nailed it on the head. There's no point in asking about these virtually impossible situations. Humans  don't even put themselves through these kinds of theoretical ethical dilemmas. 

If a human was placed in these far off situations who the fuck is going to think about the ethical dilemma in the split second before it happens?! Who's to say ones ethics will hold up against self preservation in real life scenarios?

When humans get a driver's license there's no written ethical exam that has these kind situations to sort out. The bar for a human to get in a vehicle and drive is incredibly low compared to self driving cars already. Self driving cars log thousands of not millions of hours of road time with other cars driven by humans who can be irrational and unaware. That goes to show how good of a job they're doing already. Even now the AI is still being improved. What do humans have to do? Practice some hours with a permit (not even close to a thousand hours), a written exam about road laws (no ethical dilemma situations on the exam), and pass a short driving exam (with a really qualified examiner with a bunch of certifications right? Not really, just a regular human).

Sure the AI and technology is still young and needs work. However, there's much more potential for the technology to be safer drivers than the millions of human drivers today.

